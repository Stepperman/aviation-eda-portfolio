{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚úàÔ∏è Aviation Accidents - Exploratory Data Analysis\n",
    "\n",
    "**Author**: [Il Tuo Nome]  \n",
    "**Dataset**: Aviation Safety Network (ASN) - 23,967 incidents (1919-2023)  \n",
    "**Objective**: Comprehensive EDA with OOP architecture, temporal/categorical/geospatial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "from typing import Optional, Tuple, List, Dict\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === VISUAL SETTINGS ===\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "PALETTE = 'rocket'\n",
    "\n",
    "print('‚úÖ Libraries loaded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATA LOADING ===\n",
    "def load_data():\n",
    "    paths_to_try = [\n",
    "        'aviation_accidents.csv',\n",
    "        '../data/aviation_accidents.csv',\n",
    "        '/content/aviation_accidents.csv',\n",
    "        '/content/drive/MyDrive/aviation_accidents.csv'\n",
    "    ]\n",
    "    for path in paths_to_try:\n",
    "        if os.path.exists(path):\n",
    "            print(f'üìÇ Loading from: {path}')\n",
    "            return pd.read_csv(path)\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print('‚¨ÜÔ∏è Please upload aviation_accidents.csv')\n",
    "        uploaded = files.upload()\n",
    "        return pd.read_csv(list(uploaded.keys())[0])\n",
    "    except:\n",
    "        raise FileNotFoundError('Dataset not found!')\n",
    "\n",
    "df_raw = load_data()\n",
    "print(f'üìä Shape: {df_raw.shape[0]:,} rows √ó {df_raw.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CATEGORY MAPPING ===\n",
    "CAT_MAPPING = {\n",
    "    'A1': 'Accident - Hull Loss', 'A2': 'Accident - Repairable',\n",
    "    'C1': 'Criminal - Fatal', 'C2': 'Criminal - Non-Fatal',\n",
    "    'H1': 'Hijacking - Fatal', 'H2': 'Hijacking - Non-Fatal',\n",
    "    'O1': 'Other - Hull Loss', 'O2': 'Other - Repairable',\n",
    "    'I1': 'Incident - Fatal', 'I2': 'Incident - Non-Fatal', 'U1': 'Unknown'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CleaningStats:\n",
    "    rows_original: int\n",
    "    rows_after: int\n",
    "    dates_parsed: int\n",
    "    dates_failed: int\n",
    "    fatalities_imputed: int\n",
    "    outliers_removed: int\n",
    "\n",
    "class UniversalDataEngine:\n",
    "    def __init__(self, df):\n",
    "        self.df_raw = df.copy()\n",
    "        self.df = None\n",
    "        self.cleaning_stats = None\n",
    "        self._cat_mapping = CAT_MAPPING\n",
    "    \n",
    "    def _parse_date(self, date_str):\n",
    "        if pd.isna(date_str) or date_str in ['date unk.', 'unknown', '']:\n",
    "            return pd.NaT\n",
    "        for fmt in ['%d-%b-%Y', '%Y-%m-%d', '%m/%d/%Y', '%d/%m/%Y']:\n",
    "            try:\n",
    "                return pd.to_datetime(date_str, format=fmt)\n",
    "            except:\n",
    "                continue\n",
    "        return pd.NaT\n",
    "    \n",
    "    def _extract_fatalities(self, fat_str):\n",
    "        if pd.isna(fat_str) or str(fat_str).strip() == '':\n",
    "            return (0, 0, True)\n",
    "        fat_str = str(fat_str).strip()\n",
    "        if '+' in fat_str:\n",
    "            parts = fat_str.split('+')\n",
    "            try:\n",
    "                return (int(parts[0].strip()), int(parts[1].strip()) if len(parts) > 1 else 0, False)\n",
    "            except:\n",
    "                return (0, 0, True)\n",
    "        try:\n",
    "            return (int(fat_str), 0, False)\n",
    "        except:\n",
    "            return (0, 0, True)\n",
    "    \n",
    "    def _remove_outliers_iqr(self, series, k=1.5):\n",
    "        q1, q3 = series.quantile(0.25), series.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        return (series < q1 - k*iqr) | (series > q3 + k*iqr)\n",
    "    \n",
    "    def clean(self, remove_outliers=False):\n",
    "        print('üßπ Starting cleaning...')\n",
    "        df = self.df_raw.copy()\n",
    "        rows_original = len(df)\n",
    "        \n",
    "        for col in ['type', 'registration', 'operator', 'location', 'country']:\n",
    "            df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "            df[col] = df[col].replace(['nan', 'none', '?', 'unknown', '', 'unknown country'], np.nan)\n",
    "        \n",
    "        print('  üìÖ Parsing dates...')\n",
    "        df['date_parsed'] = df['date'].apply(self._parse_date)\n",
    "        df['year_clean'] = df['date_parsed'].dt.year\n",
    "        df['month'] = df['date_parsed'].dt.month\n",
    "        df['day_of_week'] = df['date_parsed'].dt.dayofweek\n",
    "        df['decade'] = (df['year_clean'] // 10 * 10).astype('Int64')\n",
    "        \n",
    "        print('  üíÄ Extracting fatalities...')\n",
    "        fat = df['fatalities'].apply(self._extract_fatalities)\n",
    "        df['fatalities_aboard'] = fat.apply(lambda x: x[0])\n",
    "        df['fatalities_ground'] = fat.apply(lambda x: x[1])\n",
    "        df['fatalities_total'] = df['fatalities_aboard'] + df['fatalities_ground']\n",
    "        df['is_imputed'] = fat.apply(lambda x: x[2])\n",
    "        \n",
    "        df['cat_description'] = df['cat'].map(self._cat_mapping)\n",
    "        df['is_fatal'] = df['fatalities_total'] > 0\n",
    "        df['is_hull_loss'] = df['cat'].isin(['A1', 'O1', 'C1', 'H1'])\n",
    "        df['manufacturer'] = df['type'].str.split().str[0]\n",
    "        \n",
    "        df['is_outlier'] = self._remove_outliers_iqr(df['fatalities_total']) if remove_outliers else False\n",
    "        \n",
    "        self.df = df\n",
    "        self.cleaning_stats = CleaningStats(\n",
    "            rows_original, len(df), df['date_parsed'].notna().sum(),\n",
    "            df['date_parsed'].isna().sum(), df['is_imputed'].sum(),\n",
    "            df['is_outlier'].sum() if remove_outliers else 0\n",
    "        )\n",
    "        print(f'‚úÖ Done! Dates parsed: {self.cleaning_stats.dates_parsed:,}')\n",
    "        return self\n",
    "    \n",
    "    def eda_temporal(self, show_911=True):\n",
    "        df = self.df[self.df['date_parsed'].notna()].copy()\n",
    "        print('\\n' + '='*60 + '\\nüìà TEMPORAL ANALYSIS\\n' + '='*60)\n",
    "        \n",
    "        yearly = df.groupby('year_clean').agg(\n",
    "            incidents=('date_parsed', 'count'), fatalities=('fatalities_total', 'sum')\n",
    "        ).reset_index()\n",
    "        \n",
    "        fig, ax1 = plt.subplots(figsize=(14, 6))\n",
    "        c1, c2 = sns.color_palette(PALETTE, 10)[2], sns.color_palette(PALETTE, 10)[7]\n",
    "        ax1.fill_between(yearly['year_clean'], yearly['incidents'], alpha=0.3, color=c1)\n",
    "        ax1.plot(yearly['year_clean'], yearly['incidents'], color=c1, lw=2)\n",
    "        ax1.set_xlabel('Year'); ax1.set_ylabel('Incidents', color=c1)\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(yearly['year_clean'], yearly['fatalities'], color=c2, lw=2, ls='--')\n",
    "        ax2.set_ylabel('Fatalities', color=c2)\n",
    "        if show_911:\n",
    "            ax2.axvline(2001, color='red', ls=':', alpha=0.7)\n",
    "        plt.title('Aviation Incidents and Fatalities Over Time', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout(); plt.show()\n",
    "        return {'yearly': yearly}\n",
    "    \n",
    "    def eda_categorical(self):\n",
    "        df = self.df.copy()\n",
    "        print('\\n' + '='*60 + '\\nüìä CATEGORICAL ANALYSIS\\n' + '='*60)\n",
    "        \n",
    "        cat_stats = df.groupby(['cat', 'cat_description']).agg(\n",
    "            incidents=('date', 'count'), fatalities=('fatalities_total', 'sum')\n",
    "        ).reset_index().sort_values('incidents', ascending=False)\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        sns.barplot(data=cat_stats, y='cat_description', x='incidents', palette=PALETTE, ax=axes[0])\n",
    "        axes[0].set_title('Incidents by Category', fontweight='bold')\n",
    "        sns.barplot(data=cat_stats, y='cat_description', x='fatalities', palette=PALETTE, ax=axes[1])\n",
    "        axes[1].set_title('Fatalities by Category', fontweight='bold')\n",
    "        plt.tight_layout(); plt.show()\n",
    "        \n",
    "        manuf = df[df['manufacturer'].notna()].groupby('manufacturer').agg(\n",
    "            incidents=('date', 'count'), fatalities=('fatalities_total', 'sum')\n",
    "        ).reset_index().nlargest(15, 'incidents')\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        sns.barplot(data=manuf, y='manufacturer', x='incidents', palette=PALETTE, ax=axes[0])\n",
    "        axes[0].set_title('Top 15 Manufacturers by Incidents', fontweight='bold')\n",
    "        sns.barplot(data=manuf.nlargest(15, 'fatalities'), y='manufacturer', x='fatalities', palette=PALETTE, ax=axes[1])\n",
    "        axes[1].set_title('Top 15 Manufacturers by Fatalities', fontweight='bold')\n",
    "        plt.tight_layout(); plt.show()\n",
    "        return {'categories': cat_stats}\n",
    "    \n",
    "    def eda_geospatial(self):\n",
    "        df = self.df[self.df['country'].notna()].copy()\n",
    "        print('\\n' + '='*60 + '\\nüó∫Ô∏è GEOSPATIAL ANALYSIS\\n' + '='*60)\n",
    "        \n",
    "        # MAPPING ESTESO E NORMALIZZATO\n",
    "        name_map = {\n",
    "            'usa': 'United States',\n",
    "            'united states': 'United States',\n",
    "            'u.s.': 'United States',\n",
    "            'u.s. virgin isl.': 'United States',\n",
    "            'puerto rico': 'United States',\n",
    "            'guam': 'United States',\n",
    "            'u.k.': 'United Kingdom',\n",
    "            'united kingdom': 'United Kingdom',\n",
    "            'england': 'United Kingdom',\n",
    "            'scotland': 'United Kingdom',\n",
    "            'russia': 'Russia',\n",
    "            'ussr': 'Russia',\n",
    "            'russian federation': 'Russia',\n",
    "            'd.r. congo': 'Democratic Republic of the Congo',\n",
    "            'democratic republic of the congo': 'Democratic Republic of the Congo',\n",
    "            'congo': 'Republic of the Congo',\n",
    "            'china (prc)': 'China',\n",
    "            'prc': 'China',\n",
    "            'korea, south': 'South Korea',\n",
    "            'korea, north': 'North Korea',\n",
    "            'taiwan': 'Taiwan',\n",
    "            'republic of china': 'Taiwan',\n",
    "        }\n",
    "        \n",
    "        country_stats = df.groupby('country').agg(\n",
    "            incidents=('date', 'count'),\n",
    "            fatalities=('fatalities_total', 'sum')\n",
    "        ).reset_index()\n",
    "        \n",
    "        country_stats['country_normalized'] = country_stats['country'].map(\n",
    "            lambda x: name_map.get(x, x.title()) if pd.notna(x) else x\n",
    "        )\n",
    "        \n",
    "        # RI-AGGREGA dopo normalizzazione per unire territori\n",
    "        country_stats_final = country_stats.groupby('country_normalized').agg(\n",
    "            incidents=('incidents', 'sum'),\n",
    "            fatalities=('fatalities', 'sum')\n",
    "        ).reset_index().rename(columns={'country_normalized': 'country_plotly'})\n",
    "        \n",
    "        # DEBUG\n",
    "        usa_stats = country_stats_final[country_stats_final['country_plotly'] == 'United States']\n",
    "        print(f\"\\nüîç DEBUG - USA Stats:\\n{usa_stats}\\n\")\n",
    "        \n",
    "        # MAPPA 1: Incidents (Viridis)\n",
    "        fig = px.choropleth(\n",
    "            country_stats_final,\n",
    "            locations='country_plotly',\n",
    "            locationmode='country names',\n",
    "            color='incidents',\n",
    "            hover_name='country_plotly',\n",
    "            hover_data={'incidents': ':,', 'fatalities': ':,'},\n",
    "            color_continuous_scale='Viridis',\n",
    "            title='<b>Aviation Incidents by Country</b>'\n",
    "        )\n",
    "        fig.update_layout(geo=dict(showframe=False, projection_type='natural earth'))\n",
    "        fig.show()\n",
    "        \n",
    "        # MAPPA 2: Fatalities (Inferno)\n",
    "        fig2 = px.choropleth(\n",
    "            country_stats_final,\n",
    "            locations='country_plotly',\n",
    "            locationmode='country names',\n",
    "            color='fatalities',\n",
    "            hover_name='country_plotly',\n",
    "            hover_data={'incidents': ':,', 'fatalities': ':,'},\n",
    "            color_continuous_scale='Inferno',\n",
    "            title='<b>Aviation Fatalities by Country</b>'\n",
    "        )\n",
    "        fig2.update_layout(geo=dict(showframe=False, projection_type='natural earth'))\n",
    "        fig2.show()\n",
    "        \n",
    "        # BAR CHARTS\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        top_incidents = country_stats_final.nlargest(20, 'incidents')\n",
    "        sns.barplot(data=top_incidents, y='country_plotly', x='incidents', palette=PALETTE, ax=axes[0])\n",
    "        axes[0].set_title('Top 20 Countries by Incidents', fontweight='bold')\n",
    "        axes[0].set_xlabel('Number of Incidents'); axes[0].set_ylabel('')\n",
    "        \n",
    "        top_fatalities = country_stats_final.nlargest(20, 'fatalities')\n",
    "        sns.barplot(data=top_fatalities, y='country_plotly', x='fatalities', palette=PALETTE, ax=axes[1])\n",
    "        axes[1].set_title('Top 20 Countries by Fatalities', fontweight='bold')\n",
    "        axes[1].set_xlabel('Total Fatalities'); axes[1].set_ylabel('')\n",
    "        plt.tight_layout(); plt.show()\n",
    "        \n",
    "        return {'country_stats': country_stats_final}\n",
    "\n",
    "print('‚úÖ UniversalDataEngine defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RUN ANALYSIS ===\n",
    "engine = UniversalDataEngine(df_raw)\n",
    "engine.clean(remove_outliers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_results = engine.eda_temporal(show_911=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_results = engine.eda_categorical()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_results = engine.eda_geospatial()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Deep Dive: 9/11 Impact & Aircraft Lethality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 9/11 ANALYSIS ===\n",
    "print('='*60 + '\\nüî¨ 9/11 IMPACT ANALYSIS\\n' + '='*60)\n",
    "df = engine.df\n",
    "sept_11 = df[df['date'] == '11-SEP-2001']\n",
    "print(f'\\nüìÖ Events on 9/11: {len(sept_11)}')\n",
    "print(sept_11[['type', 'operator', 'fatalities_aboard', 'fatalities_ground', 'fatalities_total', 'location']])\n",
    "\n",
    "fat_2001 = df[df['year_clean']==2001]['fatalities_total'].sum()\n",
    "fat_911 = sept_11['fatalities_total'].sum()\n",
    "print(f'\\nüìä 2001 total: {fat_2001:,} | 9/11 only: {fat_911:,} ({fat_911/fat_2001*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === AIRCRAFT LETHALITY ===\n",
    "print('\\n‚úàÔ∏è AIRCRAFT LETHALITY')\n",
    "type_stats = df.groupby('type').agg(\n",
    "    incidents=('date', 'count'), fatalities=('fatalities_total', 'sum'),\n",
    "    avg_fat=('fatalities_total', 'mean')\n",
    ").reset_index()\n",
    "type_stats = type_stats[type_stats['incidents'] >= 20].sort_values('avg_fat', ascending=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "sns.barplot(data=type_stats.head(20), y='type', x='avg_fat', palette=PALETTE, ax=axes[0])\n",
    "axes[0].set_title('Top 20 Most Lethal Aircraft (Avg)', fontweight='bold')\n",
    "sns.barplot(data=type_stats.nlargest(20, 'fatalities'), y='type', x='fatalities', palette=PALETTE, ax=axes[1])\n",
    "axes[1].set_title('Top 20 by Total Fatalities', fontweight='bold')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === OPERATOR LETHALITY ===\n",
    "op_stats = df[df['operator'].notna()].groupby('operator').agg(\n",
    "    incidents=('date', 'count'), fatalities=('fatalities_total', 'sum'),\n",
    "    avg_fat=('fatalities_total', 'mean')\n",
    ").reset_index()\n",
    "op_stats = op_stats[op_stats['incidents'] >= 15]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "sns.barplot(data=op_stats.nlargest(20, 'avg_fat'), y='operator', x='avg_fat', palette=PALETTE, ax=axes[0])\n",
    "axes[0].set_title('Top 20 Operators by Avg Fatalities', fontweight='bold')\n",
    "sns.barplot(data=op_stats.nlargest(20, 'fatalities'), y='operator', x='fatalities', palette=PALETTE, ax=axes[1])\n",
    "axes[1].set_title('Top 20 Operators by Total Fatalities', fontweight='bold')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BUBBLE CHART ===\n",
    "manuf_stats = df[df['manufacturer'].notna()].groupby('manufacturer').agg(\n",
    "    incidents=('date', 'count'), fatalities=('fatalities_total', 'sum'),\n",
    "    fatal_rate=('is_fatal', 'mean')\n",
    ").reset_index().nlargest(30, 'incidents')\n",
    "\n",
    "fig = px.scatter(manuf_stats, x='incidents', y='fatal_rate', size='fatalities', color='fatalities',\n",
    "    hover_name='manufacturer', color_continuous_scale='inferno',\n",
    "    title='<b>Manufacturer Risk Profile</b><br><sup>Bubble size = Fatalities</sup>',\n",
    "    labels={'incidents': 'Incidents', 'fatal_rate': 'Fatal Rate', 'fatalities': 'Fatalities'})\n",
    "fig.update_layout(yaxis_tickformat='.0%')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SUMMARY ===\n",
    "print('='*60 + '\\nüìä FINAL SUMMARY\\n' + '='*60)\n",
    "print(f'''\\nDataset: {len(df):,} records ({df[\"year_clean\"].min():.0f}-{df[\"year_clean\"].max():.0f})\n",
    "Total fatalities: {df[\"fatalities_total\"].sum():,}\n",
    "Fatal incidents: {df[\"is_fatal\"].sum():,} ({df[\"is_fatal\"].mean()*100:.1f}%)\n",
    "9/11 fatalities: {df[df[\"date\"]==\"11-SEP-2001\"][\"fatalities_total\"].sum():,}''')"
   ]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
